{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    \n",
    "    def __init__(self, lr=0.001, n_iters=1000):\n",
    "        self.lr = lr\n",
    "        self.n_iters = n_iters\n",
    "        self.weights, self.bias = None, None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        # First, randomly initialize the weights\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.random.rand(n_features)\n",
    "        # I'm setting the bias (intercept) to zero\n",
    "        self.bias = 0.0\n",
    "        \n",
    "        for _ in range(self.n_iters):\n",
    "            y_approx = np.dot(X, self.weights) + self.bias\n",
    "            \n",
    "            # Gradient calculations w.r.t \"w\" and \"b\"\n",
    "            dw = float(1/n_samples) * np.dot(X.T, (y_approx - y))\n",
    "            db = float(1/n_samples) * np.sum(y_approx - y)\n",
    "            \n",
    "            # Update the params\n",
    "            self.weights -= self.lr * dw\n",
    "            self.bias -= self.lr * db\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_pred = np.dot(X, self.weights) + self.bias\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.data = self.read_data()\n",
    "    \n",
    "    # Read data and make dataset\n",
    "    def read_data(self):\n",
    "        data = pd.read_csv('data/iris.data', names=['f1', 'f2', 'f3', 'f4', 'species'])\n",
    "        # Replace class strings with numbers to apply linear regression\n",
    "        data.loc[(data.species == 'Iris-setosa'), 'species'] = -1.0\n",
    "        data.loc[(data.species == 'Iris-versicolor'), 'species'] = 0.0\n",
    "        data.loc[(data.species == 'Iris-virginica'), 'species'] = 1.0\n",
    "        return data\n",
    "    \n",
    "    def split_data(self, test_pct=0.2):\n",
    "        train_df = self.data.sample(frac=1-test_pct)\n",
    "        test_df = self.data.drop(train_df.index)\n",
    "        X_train = train_df[['f1', 'f2', 'f3', 'f4',]].to_numpy().astype('float64')\n",
    "        y_train = train_df[['species']].to_numpy().astype('float64').ravel()\n",
    "        X_test = test_df[['f1', 'f2', 'f3', 'f4',]].to_numpy().astype('float64')\n",
    "        y_test = test_df[['species']].to_numpy().astype('float64').ravel()\n",
    "        return X_train, y_train, X_test, y_test\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_class(prediction):\n",
    "    if prediction <= -0.33:\n",
    "        return -1\n",
    "    elif prediction > -0.33 and prediction < 0.33:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(regressor, X_test, y_test):\n",
    "    total, correct = 0, 0\n",
    "    for i, x in enumerate(X_test):\n",
    "        y_pred = round_class(regressor.predict(x))\n",
    "        y_true = int(y_test[i])\n",
    "        if y_pred == y_true:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    \n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold(k=5):\n",
    "    accs = []\n",
    "    for i in range(k):\n",
    "        X_train, y_train, X_test, y_test = dataset.split_data(test_pct=0.2)\n",
    "        regressor = LinearRegression(lr=0.001, n_iters=1000)\n",
    "        regressor.fit(X_train, y_train)\n",
    "        acc = test_model(regressor, X_test, y_test)\n",
    "        print(f'{i}. Accuracy: {acc}')\n",
    "        accs.append(acc)\n",
    "        \n",
    "    print(accs)\n",
    "    print(f'Mean classification accuracy: {sum(accs)/len(accs)}')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Accuracy: 1.0\n",
      "1. Accuracy: 0.9333333333333333\n",
      "2. Accuracy: 0.9666666666666667\n",
      "3. Accuracy: 1.0\n",
      "4. Accuracy: 1.0\n",
      "[1.0, 0.9333333333333333, 0.9666666666666667, 1.0, 1.0]\n",
      "Mean classification accuracy: 0.9800000000000001\n"
     ]
    }
   ],
   "source": [
    "k_fold(k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asheesh",
   "language": "python",
   "name": "asheesh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
